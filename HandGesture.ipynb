{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandGesture",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1TgJTnr4N-lDJjYldzycWL-L0Ns2An33Y",
      "authorship_tag": "ABX9TyMZCHnSRHLWNL9cyfCs3yCa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C0oho4eQbeU"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeCsx_Nvzq9J"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YBvUCtC0IN4"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1LY2kUaXY62IxGXsKziS-TZsxBnIFwCHK'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('kaggle.json') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrPb-5bQ1ixt"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_05U2nX2Xxi"
      },
      "source": [
        "!kaggle datasets download -d toxicmender/20bn-jester"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og8U32tg4aFf"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"20bn-jester.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkr8HXLjTe7F"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import seaborn as sbn\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUdltNd8UYg5"
      },
      "source": [
        "**Making smaller set**\n",
        "\n",
        "The classes (labels) we want to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkGIU_dUUSm7"
      },
      "source": [
        "LABELS = {\n",
        "    \"Swiping Right\": 0,\n",
        "    \"Swiping Left\": 1,\n",
        "    \"No gesture\": 2,\n",
        "    \"Thumb Up\": 3,\n",
        "    \"Sliding Two Fingers Up\": 4,\n",
        "    \"Sliding Two Fingers Down\": 5,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85tV1h3SUtPx"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNga_mEAU1fg"
      },
      "source": [
        "BASE_PATH = '/content'\n",
        "TRAIN_DATA_CSV = BASE_PATH + '/Train.csv'\n",
        "TEST_DATA_CSV = BASE_PATH + '/Test.csv'\n",
        "VAL_DATA_CSV = BASE_PATH + '/Validation.csv'\n",
        "\n",
        "TRAIN_SAMPLES_PATH = BASE_PATH + '/Train/'\n",
        "TEST_SAMPLES_PATH = BASE_PATH + '/Test/'\n",
        "VAL_SAMPLES_PATH = BASE_PATH + '/Validation/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYv9_PEiVFj9"
      },
      "source": [
        "Training targets, you can use your custom csv file if you already created it before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzLJn2DHVIBG"
      },
      "source": [
        "targets = pd.read_csv(TRAIN_DATA_CSV)\n",
        "targets = targets[targets['label'].isin(LABELS.keys())]\n",
        "targets['label'] = targets['label'].map(LABELS)\n",
        "targets = targets[['video_id', 'label']]\n",
        "targets = targets.reset_index()\n",
        "targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1qk_6lOWhhv"
      },
      "source": [
        "Validation targets, you can use your custom csv file if you already created it before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slnOMvUiWkAs"
      },
      "source": [
        "targets_validation = pd.read_csv(VAL_DATA_CSV)\n",
        "targets_validation = targets_validation[targets_validation['label'].isin(LABELS.keys())]\n",
        "targets_validation['label'] = targets_validation['label'].map(LABELS)\n",
        "targets_validation = targets_validation[['video_id', 'label']]\n",
        "targets_validation = targets_validation.reset_index()\n",
        "targets_validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AfjqtBBWsUh"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ2nZacaZ3Ue"
      },
      "source": [
        "# image specification\n",
        "img_rows,img_cols=64, 64 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTTdLoyWWuhw"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    \"\"\"\n",
        "    Converts numpy array of RGB to grayscale\n",
        "    \"\"\"\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPi0TFjqW0MC"
      },
      "source": [
        "def resize_frame(frame):\n",
        "    \"\"\"\n",
        "    Resizes frames to (64, 64)\n",
        "    \"\"\"\n",
        "    frame = img.imread(frame)\n",
        "    frame = cv2.resize(frame, (img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2uo2TNiW6yv"
      },
      "source": [
        "The videos do not have the same number of frames, here we try to unify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzHisiMpW77x"
      },
      "source": [
        "hm_frames = 30 # number of frames\n",
        "def get_unify_frames(path):\n",
        "    \"\"\"\n",
        "    Unifies number of frames for each training\n",
        "    \"\"\"\n",
        "    offset = 0\n",
        "    # pick frames\n",
        "    frames = os.listdir(path)\n",
        "    frames_count = len(frames)\n",
        "    # unify number of frames \n",
        "    if hm_frames > frames_count:\n",
        "        # duplicate last frame if video is shorter than necessary\n",
        "        frames += [frames[-1]] * (hm_frames - frames_count)\n",
        "    elif hm_frames < frames_count:\n",
        "        # If there are more frames, then sample starting offset\n",
        "        # diff = (frames_count - hm_frames)\n",
        "        # offset = diff-1 \n",
        "        frames = frames[0:hm_frames]\n",
        "    return frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgdpJj50XIpc"
      },
      "source": [
        "Adjust data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So1A44SCXKjx"
      },
      "source": [
        "# Adjust training data\n",
        "train_targets = [] # training targets \n",
        "test_targets = [] # testing targets\n",
        "\n",
        "new_frames = [] # training data after resize & unify\n",
        "new_frames_test = [] # testing data after resize & unify\n",
        "\n",
        "for idx, row in tqdm(targets.iterrows(), total=len(targets)):\n",
        "    if idx % 4 == 0:\n",
        "        continue\n",
        "    \n",
        "    partition = [] # one training\n",
        "    # Frames in each folder\n",
        "    frames = get_unify_frames(TRAIN_SAMPLES_PATH + str(row['video_id']))\n",
        "    if len(frames) == hm_frames: # just to be sure\n",
        "        for frame in frames:\n",
        "            frame = resize_frame(TRAIN_SAMPLES_PATH + str(row['video_id']) + '/' + frame)\n",
        "            partition.append(rgb2gray(frame))\n",
        "            if len(partition) == 15: # partition each training on two trainings.\n",
        "                if idx % 6 == 0:\n",
        "                    new_frames_test.append(partition) # append each partition to training data\n",
        "                    test_targets.append(row['label'])\n",
        "                else:\n",
        "                    new_frames.append(partition) # append each partition to test data\n",
        "                    train_targets.append(row['label'])\n",
        "                partition = []\n",
        "\n",
        "train_data = np.asarray(new_frames, dtype=np.float16)\n",
        "\n",
        "del new_frames[:]\n",
        "del new_frames\n",
        "\n",
        "\n",
        "test_data = np.asarray(new_frames_test, dtype=np.float16)\n",
        "del new_frames_test[:]\n",
        "del new_frames_test\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ChQwzCX9Bx"
      },
      "source": [
        "# we do the same for the validation data\n",
        "cv_targets = []\n",
        "new_frames_cv = []\n",
        "for idx, row in tqdm(targets_validation.iterrows(), total=len(targets_validation)):\n",
        "    if idx % 4 == 0:\n",
        "        continue\n",
        "\n",
        "    partition = []\n",
        "    # Frames in each folder\n",
        "    frames = get_unify_frames(VAL_SAMPLES_PATH+str(row[\"video_id\"]))\n",
        "    for frame in frames:\n",
        "        frame = resize_frame(VAL_SAMPLES_PATH+str(row[\"video_id\"])+'/'+frame)\n",
        "        partition.append(rgb2gray(frame))\n",
        "        if len(partition) == 15:\n",
        "            new_frames_cv.append(partition)\n",
        "            cv_targets.append(row['label'])\n",
        "            partition = []\n",
        "                \n",
        "cv_data = np.array(new_frames_cv, dtype=np.float16)\n",
        "del new_frames_cv[:]\n",
        "del new_frames_cv\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWcwjhIX-73"
      },
      "source": [
        "print(f\"Training = {len(train_data)}/{len(train_targets)} samples/labels\")\n",
        "print(f\"Test = {len(test_data)}/{len(test_targets)} samples/labels\")\n",
        "print(f\"Validation = {len(cv_data)}/{len(cv_targets)} samples/labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teG-Sg_vMtVI"
      },
      "source": [
        "nb_classes = 6\n",
        "patch_size = 15    # img_depth or number of frames used for each video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrNMlRC-tvZo"
      },
      "source": [
        "num_samples = len(train_data)\n",
        "print(num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "truQO_5zYX62"
      },
      "source": [
        "Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDplRZ2OYZZb"
      },
      "source": [
        "# Normalisation: training\n",
        "print('old mean', train_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images  = scaler.fit_transform(train_data.reshape(-1, 15*64*64))\n",
        "del train_data\n",
        "print('new mean', scaled_images.mean())\n",
        "\n",
        "scaled_images  = scaled_images.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYZGll5DYiQA"
      },
      "source": [
        "# Normalisation: test\n",
        "print('old mean', test_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images_test = scaler.fit_transform(test_data.reshape(-1, 15*64*64))\n",
        "del test_data\n",
        "print('new mean', scaled_images_test.mean())\n",
        "\n",
        "scaled_images_test = scaled_images_test.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a97zQT9BYj-S"
      },
      "source": [
        "# Normalisation: validation\n",
        "print('old mean', cv_data.mean())\n",
        "\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaled_images_cv  = scaler.fit_transform(cv_data.reshape(-1, 15*64*64))\n",
        "del cv_data\n",
        "print('new mean',scaled_images_cv.mean())\n",
        "\n",
        "scaled_images_cv  = scaled_images_cv.reshape(-1, 15, 64, 64, 1)\n",
        "print(scaled_images_cv.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3B5ObuvZGtT"
      },
      "source": [
        "del scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomvawMeZobc"
      },
      "source": [
        "**Make sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8400WEXZrh4"
      },
      "source": [
        "y_train = np.array(train_targets, dtype=np.int8)\n",
        "y_test = np.array(test_targets, dtype=np.int8)\n",
        "y_val = np.array(cv_targets, dtype=np.int8)\n",
        "del train_targets\n",
        "del test_targets\n",
        "del cv_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVoLhKMfZxNB"
      },
      "source": [
        "x_train = scaled_images\n",
        "x_test = scaled_images_test\n",
        "x_val = scaled_images_cv\n",
        "del scaled_images\n",
        "del scaled_images_test\n",
        "del scaled_images_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqbo7LOFZ3ay"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atHPxUAhPPpR"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
        "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
        "from keras.optimizers import SGD, RMSprop, Adadelta\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "\n",
        "import theano\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn import cross_validation\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5vMknt-Z96u"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKIJgyeraAQN"
      },
      "source": [
        "weight_decay = 0.005\n",
        "from keras import regularizers\n",
        "model = Sequential()\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2),input_shape=(patch_size, 64, 64, 1)))\n",
        "\n",
        "model.add(Conv3D(8,(5,5,5),activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "\n",
        "model.add(Conv3D(32,(3,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "#model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "#model.add(Conv3D(64,(3,3,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "#model.add(MaxPooling3D(pool_size=(1, 2, 2 )))\n",
        "\n",
        "\n",
        "\n",
        "#model.add(Conv3D(128,3,3,3, activation='relu'))\n",
        "#model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
        "#border_mode='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ConvLSTM2D(40,(3,3)))\n",
        "model.add(Flatten())\n",
        "#model.add(GlobalAveragePooling3D())\n",
        "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sc-l4CeUr_O"
      },
      "source": [
        "import keras\n",
        "# Define model\n",
        "#high resolution network\n",
        "from keras import regularizers\n",
        "weight_decay = 0.005\n",
        "model = Sequential()\n",
        "model.add(Conv3D(4,(3,7,7),\n",
        "                        input_shape=(patch_size, img_cols, img_rows, 1),\n",
        "                 activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "print(model.output_shape)\n",
        "model.add(Conv3D(8,(3,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "print(model.output_shape)\n",
        "model.add(Conv3D(32,(3,5,5), activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(MaxPooling3D(pool_size=(1, 1, 2)))\n",
        "print(model.output_shape)\n",
        "                  \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(nb_classes,kernel_initializer='normal',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5fgebvaTGX"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LoDAbJCVf-a"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, show_shapes=True,\n",
        "               to_file=os.path.join('model.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKg1Fvl5aymc"
      },
      "source": [
        "sgd = SGD(lr=0.005,  momentum=0.9, nesterov=False)\n",
        "rms = RMSprop(decay=1e-6)\n",
        "ada = Adadelta(lr=0.1,decay=1e-6)\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              #optimizer=sgd,\n",
        "              optimizer=ada,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZgytqjqQHVv"
      },
      "source": [
        "# Split the data\n",
        "X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(x_train, y_train, test_size=0.2, random_state=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODv3ntfRdNv"
      },
      "source": [
        "import os\n",
        "#os.chdir('///home/jovyan/program/DL/11_1下tensorflow_simpson')\n",
        "save_dir = os.path.join(os.getcwd(),'saved_model')\n",
        "print(os.getcwd())\n",
        "model_name = \"3DCNN_LRN_112_6_jester\"\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
        "                            save_best_only=True, verbose=1)\n",
        "#earlystop\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nSiiv8bMc2"
      },
      "source": [
        "**Start Running**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOwoJR0DbUJ9"
      },
      "source": [
        "batch_size = 80\n",
        "nb_epoch = 100\n",
        "#steps_per_epoch=int((len(x_train))/batch_size)\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
        "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
        "hist = model.fit(\n",
        "    X_train_new,\n",
        "    y_train_new,\n",
        "    validation_data=(X_val_new,y_val_new),\n",
        "    batch_size = batch_size,\n",
        "    epochs = nb_epoch,\n",
        "    shuffle=True,\n",
        "    callbacks=[checkpoint,lr_reducer]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJRmzJlS4ziP"
      },
      "source": [
        "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
        "print(\"Accuracy:\" + str(acc))\n",
        "epochs = [i for i in range(100)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = hist.history['acc']\n",
        "train_loss = hist.history['loss']\n",
        "val_acc = hist.history['val_acc']\n",
        "val_loss = hist.history['val_loss']\n",
        "fig.set_size_inches(16,9)\n",
        "\n",
        "ax[0].plot(epochs , train_acc,'go-',label='Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc,'ro-',label='Testing Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss,'g-o',label='Training Loss')\n",
        "ax[1].plot(epochs , val_loss,'r-o',label='Testing Loss')\n",
        "ax[1].set_title('Testing Accuracy & Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQDCy-2w0nkY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCJkJPCXitSi"
      },
      "source": [
        "model.save_weights('/w.tf', save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdHxpXXVnG7G"
      },
      "source": [
        "**Make Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DGZXAzonL9J"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYgTKKCknZHc"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iww1i12XnaQU"
      },
      "source": [
        "np.unique(y_test, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gncuNhVlnd29"
      },
      "source": [
        "Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMssBvRkngZ1"
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRY1NNXnkXC"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY4-oRFwnp4A"
      },
      "source": [
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFdTw0VtnsmZ"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Ru4DsPny8K"
      },
      "source": [
        "**Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6bf0sinnwVS"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ep55lLn__Y"
      },
      "source": [
        "labels = list(LABELS.keys())\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnUaOdploC9T"
      },
      "source": [
        "**1. Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQQZcc9roGe_"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "df_cm = pd.DataFrame(cm, range(6), range(6))\n",
        "plt.figure(figsize=(15,15))\n",
        "sbn.set(font_scale=1.4) # for label size\n",
        "sbn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h05qbbSLoP8q"
      },
      "source": [
        "**2. Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYAoht9oR2N"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptSNcutSoaA_"
      },
      "source": [
        "**3. Precision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF7RDrSRoYNJ"
      },
      "source": [
        "precision_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMN-jZmBoqxP"
      },
      "source": [
        "**4. Recall**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXBO4juotSL"
      },
      "source": [
        "recall_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE5NVuQVo0hE"
      },
      "source": [
        "**5. F1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRBmZhRyowce"
      },
      "source": [
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}